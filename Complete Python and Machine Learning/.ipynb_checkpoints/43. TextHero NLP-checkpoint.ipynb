{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42396b10-5fab-487d-8c3f-8d6f9898beac",
   "metadata": {},
   "source": [
    "## Text Hero\n",
    "Under the hoods, Texthero makes use of multiple NLP and machine learning toolkits such as Gensim, NLTK, SpaCy and scikit-learn. You don't need to install them all separately, pip will take care of that.\n",
    "\n",
    "Texthero include tools for:\n",
    "\n",
    "* Preprocess text data: it offers both out-of-the-box solutions but it's also flexible for custom-solutions.\n",
    "* Natural Language Processing: keyphrases and keywords extraction, and named entity recognition.\n",
    "* Text representation: TF-IDF, term frequency, and custom word-embeddings (wip)\n",
    "* Vector space analysis: clustering (K-means, Meanshift, DBSAN and Hierarchical), topic modelling (wip) and interpretation.\n",
    "* Text visualization: vector space visualization, place localization on maps (wip).\n",
    "\n",
    "Supported representation algorithms:\n",
    "\n",
    "* Term frequency (count)\n",
    "* Term frequency-inverse document frequency (tfidf)\n",
    "\n",
    "Supported clustering algorithms:\n",
    "\n",
    "* K-means (kmeans)\n",
    "* Density-Based Spatial Clustering of Applications with Noise (dbscan)\n",
    "* Meanshift (meanshift)\n",
    "\n",
    "Supported dimensionality reduction algorithms:\n",
    "\n",
    "* Principal component analysis (pca)\n",
    "* t-distributed stochastic neighbor embedding (tsne)\n",
    "* Non-negative matrix factorization (nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0abec2-81d5-4c5c-a4ff-73165346886e",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "* conda activate texthero\n",
    "* pip install ipykernel\n",
    "* Add the kernel to Jupyter : python -m ipykernel install --user --name=texthero --display-name \"Python (texthero)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11ec764-15bc-457c-88c3-c4002562a4cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'texthero'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtexthero\u001b[39;00m\n\u001b[0;32m      2\u001b[0m help(texthero)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'texthero'"
     ]
    }
   ],
   "source": [
    "import texthero\n",
    "help(texthero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c79a59-1ae4-438f-8052-3713ea1eed12",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508bd11-be4b-4eeb-99e8-9f011e9f8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "text=\"It's a pleasant   day at Bangalor√©; at / (10:30) am\"\n",
    "series=pd.Series(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f0f51-966b-44a1-8436-13360f321ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35e7d6-d06c-4e77-9946-603f6a319b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import texthero as hero\n",
    "\n",
    "hero.remove_digits(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710fad7-7da0-4b76-b28d-ce9a308563de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove punctuations\n",
    "hero.remove_punctuation(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f4b81-18fc-4f77-b172-28148e993ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove Brackets\n",
    "hero.remove_brackets(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435b380-9aef-4f9e-b51e-1c430f0db74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero.remove_diacritics(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd28e23-e88d-477c-bd9a-3151ef29d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero.remove_whitespace(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fedcc-c012-4149-baf6-39e378cef918",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stopwords\n",
    "hero.remove_stopwords(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ef4d4-cf56-4305-8dab-eaf8771276dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero.clean(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd1c56-9fcf-47e1-b73b-06760946cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "   \"https://github.com/jbesomi/texthero/raw/master/dataset/bbcsport.csv\"\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94072934-7ef0-48fc-a844-fe8e4d25ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "###PCA\n",
    "import texthero as hero\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "   \"https://github.com/jbesomi/texthero/raw/master/dataset/bbcsport.csv\"\n",
    ")\n",
    "\n",
    "df['pca'] = (\n",
    "   df['text']\n",
    "   .pipe(hero.clean)\n",
    "   .pipe(hero.tfidf)###vectorizing\n",
    "   .pipe(hero.pca)\n",
    ")\n",
    "hero.scatterplot(df, 'pca', color='topic', title=\"PCA BBC Sport news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b7aaa-78f6-43e7-8b91-a877873fc82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee932771-b45a-41c0-85cd-66820a55437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import texthero as hero\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://github.com/jbesomi/texthero/raw/master/dataset/bbcsport.csv\"\n",
    ")\n",
    "\n",
    "df['tfidf'] = (\n",
    "    df['text']\n",
    "    .pipe(hero.clean)\n",
    "    .pipe(hero.tfidf)\n",
    ")\n",
    "### Kmeans\n",
    "\n",
    "df['kmeans_labels'] = (\n",
    "    df['tfidf']\n",
    "    .pipe(hero.kmeans, n_clusters=5)\n",
    "    .astype(str)\n",
    ")\n",
    "\n",
    "df['pca'] = df['tfidf'].pipe(hero.pca)\n",
    "\n",
    "hero.scatterplot(df, 'pca', color='kmeans_labels', title=\"K-means BBC Sport news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30028049-f6c7-4222-98b4-33c9d3a35437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (texthero)",
   "language": "python",
   "name": "texthero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
